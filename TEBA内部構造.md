■ TEBA の内部の概要

□ cparse.pl (CParser.pm)

  cparse.pl は、CParser.pm を呼び出すラッパーであり、基本的な処理は
  CParser.pm に記述されている。処理は解析対象のテキストを以下の順に
  処理していく。

    (1) Tokenizer で字句に分解する
    (2) 前処理指令について解析する
    (3) 括弧の対応関係について解析する
    (4) マクロ文を解析する
    (5) 文レベルの粗い解析をする
    (6) 名前空間の切り分けを行う
    (7) 式レベルの解析を行う
    (8) 補正処理と宣言の識別を行う

  これらの処理は可能な限り、字句系列の書換えルールとして実現している。
  書換えルールでは、様々な要素の組み合わせに対応できるよう、目的の構造の
  核となる部分を特定して、一時的な仮想字句を配置してから、その仮想字句を
  基としてさらにルールを適用していく手法が取られている。このとき、仮想字句
  の型名は、必ず "_" で始めるようにしており、解析の終了までには削除れるか、
  名前が変更される。よって、解析結果に "_" を含む型が含まれたときは、
  何らかの理由で解析に失敗していることを意味する。また、型名を見ることで、
  問題が起きたルールを見つける手掛りとなる。

  (1) Tokenizer は字句解析器であり、TEBA/token.def に従って字句に分解する。
  分解された結果は、属性付き字句系列となる。

  (2) 前処理指令のみを解析し、前処理指令の範囲を確定する。これにより、
  以後の解析で、前処理指令を空白として扱ったり、前処理指令の内部に閉じた
  構文解析が可能になる。(TEBA/prep.rules)

  (3) 括弧の対応関係を解析し、対応する組には同じ内部識別記号を割り当てる。
  また、対応する括弧の数が合わないマクロ定義があった場合には、テキストを
  持たない仮想字句として、疑似的な括弧を挿入し、必ず組が閉じるようにする。
  (TEBA/BracketsID.pm)

  (4) マクロを文や宣言のように使用していて、かつ、行末がセミコロンでは
  終わっていない場合に、仮想字句として擬似的なセミコロンを追加して、
  整合を取る。なお、これはヒューリスティックな規則であり、完全ではない。
  (TEBA/macro-stmt.rules)

  (5) 文レベルまでの解析をする。式のレベルの解析をしない理由は、型と
  それ以外の識別を区別できないと、構文木を唯一に決められない曖昧な
  表現があるためである。例えば (x)(y) は x が型か関数名かによって木構造が
  異なる。そのため、先に曖昧さの少ない文レベルまで解析し、識別子が
  どの名前空間に属するかを推定してから、式レベルの解析を行う。
  (TEBA/CoarseGrainedParser.pm)

  (6) 名前空間の切り分けは、識別子をタグ、ラベル、メンバ、マクロ、型、
  変数または関数に分ける。マクロを使った特殊な形がない限り、タグ、ラベル、
  メンバは前後の文脈から正確に決まる。マクロは、本来は名前空間に属さない
  分類であるが、前処理指令の中など明確にマクロ名とわかるものだけを
  取り扱う。型は、文脈から推定して型と確信が持てるものだけを置き換える。
  最終的に残った識別子を変数または関数として扱う。(TEBA/namespace.rules)

  (7) 式レベルの解析は、優先度に基づいて解析をしていくのみである。
  ただし、+ や - のように単項演算子と2項演算子の両方がありうるものを
  区別するために、単項演算子の文脈で出現する演算子を識別し、型名を
  OP_U に変更して区別する。また、カンマは演算子であるが、線形構造を
  表現することに意味があるとは思われないので、解析ルールを定義して
  いるが、実際には適用していない。(TEBA/EParser)

  (8) 引数に文を含むマクロ呼び出しや、末尾にセミコロンがないが文や
  宣言と同様に扱うマクロ文など、解析が正しく行えない事例に対して、
  解析結果を補正を行う。この時点では、式の解析が行われているので、
  正しく解析されていればありえない字句の並びから誤った箇所を同定し、
  補正を行う。また、宣言の識別はこの最終段階で行う。これは、補正で
  新たに文が追加されることと、宣言の識別に依存するルールは存在しない
  からである。

□ CoarseGrainedParser.pm

  文レベルまでの構造を解析する。その処理は大きく3つの段階で構成している。

    (1) 文の区切り位置の同定(制御文の入れ子は除く)  
    (2) 制御文の入れ子の解析の準備
    (3) 制御文の入れ子の解析

  (1) の段階で、セミコロンの直後など、文の区切りとなると想定される箇所に
  B_ST または E_ST を入れていく。なお、宣言はすべて文として扱う。宣言の
  初期化式の中など、文脈を調べないと区別がつかない箇所は、まず、文の区切り
  として扱い、そのあと、文が出現しない特定の文脈を特定してから区切りを取り
  除く。また、この段階では、制御文は識別せず、式文やジャンプ文など、制御文
  以外の文を識別する。B_ST と E_ST は組にならないといけないが、片方ずつ
  入れているので、マクロの定義の中などでは、数が合わない可能性があり、
  それも補正している。 (TEBA/parser-stage1.rules)

  (2) 制御文の入れ子の解析の準備として、条件式を含む頭の部分を識別し、これを
  次の段階の出発点とする。また、関数の識別を行い、書換えの適用範囲が
  関数をまたがる危険性を解消している。(TEBA/parser-stage2.rules)

  (3) 条件式の部分から右側の文を取り込むように範囲を広げ、それを文として
  識別する。入れ子になっているので、再帰的に適用する。なお、構文上、ラベルは
  文の外側に存在するものだが、一旦、中に移動させてから制御構造の入れ子を
  識別している。これは、制御文の本文が複合文ではなく、かつ、ラベルが付与
  されている場合に正しく解析できないためである。(補足:グループを使えば
  このような手間を避けられる可能性が、複雑なルールは大量のバックトラックを
  引き起すことがあるので注意が必要である。) (TEBA/parser-condstmt.rules)

□ EParser.pm

  EParser.pm は式レベルの解析をするにあたり、以下の書換えルールを適用して
  いく。ファイル名の p の後ろの数字は、演算子の優先度のレベルを表しており、
  優先度の高いものから徐々に解析していく。

    TEBA/expr-base.rules
    TEBA/expr-p01.rules
    TEBA/expr-p02.rules
    TEBA/expr-p03-12.rules
    TEBA/expr-p13.rules
    TEBA/expr-p14.rules
    TEBA/expr-p15.rules

  expr-base.rules は、解析の準備であり、変数などの終端要素や括弧で囲われた
  式など、解析の出発点となる要素を識別する。また、単項演算子と二項演算子を
  区別するために、単項演算子が出現する文脈に基づき、単項演算子の型名を
  OP_U に変更している。優先度 03 から 12 の演算子はルールの構成が同じであり、
  可読性の観点で1つのファイルにまとめている。それ以外は、ルールに特徴があり、
  別のファイルにまとめている。例えば、優先度 02 と 13 は、再帰的に繰り返す
  必要がある。なお、すでに述べた通り、現在の実装では、カンマ演算子の解析を
  実装している expr-p15.rules は適用していない。

  演算子は、同じ優先度の演算子に関して、左結合と右結合があり、その結合の
  方向に従って式を識別していく必要がある。そこで、各ルールでは、一時的な
  仮想字句を使って、正しく結合するように処理している。この一時的な仮想字句の
  型の名前には演算子の優先度を入れており、正しく処理されなかったときに、
  どの規則で問題が起きたか把握できるようになっている。また、右結合の演算子に
  ついて書換えルールを定義する場合、 演算子の左側に任意の式が存在するので、
  一つのルールの中に選択を含む箇所が増え、大量のバックトラックが発生しやすい。
  よって、選択を減らすようルールを分解して記述している。

□ rewrite.pl, ProgTrans.pm

  rewrite.pl は ProgTrans.pm の機能を利用してプログラムの書換えを実現する。
  基本的な処理の流れは以下の通りである。

    (1) プログラムパターンの %before と %after をそれぞれ構文解析する
    (2) 各結果に対して、パターン変数や空白類の正規化等の補正を行う。
    (3) 各結果から、字句系列のパターンの前と後を生成し、書換えルールを
        構成する。
    (4) RewriteTokens を用いて、入力に対して書換えを適用する。

  プログラムパターンは、プログラム本来の記述とほぼ同じであるが、パターン
  変数などの拡張があり、そのままの CParser.pm では解析できない。しかし、
  CParser.pm には、字句の定義の追加や、処理の途中にフィルタを加える方法が
  用意されており、それを用いて拡張している。なお、フィルタをどこに追加すれば
  よいかは、CParser.pm の各段階を正しく理解していないと判断できない。

  %before と %after の各パターンを構文解析によって字句系列に変換したあと、
  それぞれ字句系列のパターンに変換するが、パターン変数や空白などに関しての
  特別な処理が必要である。例えば、文に適合する STMT 型の変数 ${stmt:STMT} を
  使用した場合、構文解析の段階では文として解析する方法がなく、識別子として
  解析を行う。その場合、パターン変数の前後は式を表す B_P と E_P に囲まれ、
  文に適合しなくなる。よって、このような型に合わせて不要な仮想字句を削除する
  ことが必要である。

  空白についても特別な処理を行う。すなわち、%before に記述された空白類と、
  実際に適合させたいプログラムの断片の空白類が一致するという保証はなく、
  空白類が入りうる箇所すべてに任意の空白が存在することを前提とする必要がある。
  一方、文や式など仮想字句で囲われる非終端記号については、その開始と
  終了は空白ではないので、そこに空白が入ることを前提にすべきではない。
  よって、すべての字句間にスペースを入れたあと、仮想字句の直後または直前の
  空白を削除し、あらゆる空白の連続を1つの空白に置き換えるという正規化を
  行い、その空白を任意の空白類に適合する変数に置き換えるという処理をしている。

  さらに、-s オプションを用いた場合には、%before で適合した空白類が
  %after に保存されるよう、%after 側の字句系列の間に空白類の参照が
  含まれるように変換を行う。基本的な戦略として、%before の空白類の前後の
  テキストを持つ字句のうち、%after 側にも出現していて、かつ、最も近いものを
  特定し、すべての空白類はその字句に付随するように移るという方法を
  採用している。空白類を削除しないので、必ずしも適切な処理とはならないが、
  直感的にはほぼ位置が変わらないように見える結果を得られる。

  書換えそのものは、RewriteTokens を用いて行うが、内部識別記号が重複するなど
  字句系列としての整合性が崩れることがあるので、内部識別記号の再割り当てなど
  正規化を行う。また、パターンの構文解析は、入力となるプログラムの構文解析と
  同じ CParser.pm を、上位互換となる形で拡張しているので、パターン変数などの
  独自の記法以外については、例え、解析結果が間違っていたとしても、同じ結果に
  なり、確実に書換えが適用できる。

  記述できるパターンは、必ず構文解析ができる状態でなければならない。
  したがって、式の一部や単体の case ラベルなど、特定の文脈の中でしか
  構成できない要素をそのまま記述すると、B_ST や E_ST が意図しない位置に
  補完され、目的を果せない。その場合には、文脈を含めて記述し、目的の
  範囲を ${%begin} と ${%end} で囲うことで、指定できる。

□ id_unify.pl (IdUnify.pm)

  二つの字句系列間で、内部識別記号を統一する。この基本的な処理の流れは以下の
  通りである。

    (1) すべての識別記号を無視して、LCS により、字句の対応関係を求める。
    (2) 対応する字句の組を取り出し、それらの字句および同じ識別記号を持つ
        字句には、統一した字句番号を与える。
    (3) 統一した字句番号以外は無視して、再び LCS によって対応関係を求め、
        組がなくなるまで (2) に戻って統一を行う。

  Algorithm::Diff の実行性能に大きく依存しており、大規模なファイルでは時間が
  かかる。また、実際には、上記の流れより複雑な処理をしている。例えば、比較
  する字句系列は、先頭の方は一致しやすいという性質があるので、LCS を求める
  前に、一致する先頭の部分について、対応する内部識別記号を求め、それらは
  確定したものとして、残りの部分だけについて、LCS を求めている。

□ preg.pl

  プログラムのパターンに適合する部分を探すツールである。検索は、rewrite.pl
  と同様に字句系列に対するパターンに変換して適用する。よって、パターンに
  変換する部分は ProgTrans.pm の %before に関する処理を利用している。
 
  検索した箇所を出力するために、まず、与えられたパターンに適合した箇所の
  前後に仮想字句を入れ、その仮想字句を用いてオプションに合わせた出力を
  している。仮想字句は、適合開始箇所に _RB と _MB を、終了箇所に _ME と
  _RE を用いている。2つ用いている理由は、適合した範囲と出力する範囲が
  異なる場合に対処するためである。 _RB と _RE は出力する範囲を、_MB と
  _ME は適合した範囲を表し、-s オプションで出力範囲を拡大するときは
  _RB と _RE の位置を変更している。

  適合した範囲を仮想字句で表現しているので、-t オプションを使って
  出力すれば、そのあと、適合箇所を別のツールで処理することも可能である。
